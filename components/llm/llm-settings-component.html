<div class="llm-settings-component">
    <div class="input-group b-mar-gap2">
        <label for="engine-selector">
            LLM Engine
            <help-component>
                <p>
                    Due to cost of running AI, this open source app relies on you to provide your AI and models. There are many options:
                </p>
                <table>
                    <thead>
                        <th>Name</th>
                        <th>Description</th>
                        <th>API Key</th>
                    </thead>
                    <tbody>
                        <tr v-for="engine of config.llm.engines">
                            <th>
                                <ext-link :href="engine.website">{{ engine.name }}</ext-link>
                            </th>
                            <td v-text="engine.description"></td>
                            <td>
                                <ext-link v-if="engine.apiKeyWebsite" :href="engine.apiKeyWebsite">Get</ext-link>
                            </td>
                        </tr>
                    </tbody>
                </table>
            </help-component>
        </label>
        <div class="subtle-hint">You can pre-fill the settings</div>
        <div class="input-button-pair">
            <select
                id="engine-selector"
                v-model="selectedEngine"
            >
                <option
                    v-for="engine of config.llm.engines"
                    :value="engine"
                >{{ engine.name }}</option>
            </select>
            <button v-if="selectedEngine" @click="prefillSelectedEngine()">Prefill</button>
        </div>
    </div>
    <div class="b-mar-gap2">
        <div class="input-group">
            <label for="llm-api-settings-component__base-url">
                Base URL
                <div class="subtle-hint">Make sure the URL ends with <code>/</code></div>
            </label>
            <input
                type="url"
                v-model="llmClone.baseUrl"
                required="required"
                id="llm-api-settings-component__base-url" />
            <text-block-component type="error" v-if="!llmClone.baseUrl?.toLowerCase().endsWith('/')">
                The URL needs to end with a slash. In the future the code will do it automatically but for now, please
                <button class="small" @click="llmClone.baseUrl += '/'">Append Slash</button>.
            </text-block-component>
        </div>
        <div class="input-group">
            <label>
                <input type="checkbox" v-model="llmClone.useApiKey">
                <icon-component name="key"></icon-component>
                API Key
                <div class="subtle-hint">
                    You can write anything if not required
                </div>
            </label>
            <input
                type="text"
                v-if="llmClone.useApiKey"
                v-model="llmClone.apiKey"
                autocomplete="llm-api-key"
                required="required"
                :id="llm-api-key" />
            <text-block-component type="warning" v-if="llmClone.useApiKey && llmClone.baseUrl?.toLowerCase().startsWith('http://')">
                The API Key is not stored remotely or shared with anyone but it will be in the requests that are made to the API endpoints.
                Make sure to use HTTPS endpoints so your chat and/or API key doesn't leak.
            </text-block-component>

        </div>
        <div class="input-group b-mar-gap2">
            <label for="llm-api-settings-component__model-id">
                Model
                <help-component>
                    <p>
                        Please pick a model that:
                        <ul>
                            <li>Supports text-generation (we use no multi-modal capability as of now)</li>
                            <li>Supports function calls</li>
                            <li>Is instruction tuned</li>
                            <li>Has at least 8k Token context window and able to call functions. (An upcoming RAG implementation replaces the current CAG and token consumption)</li>
                        </ul>
                    </p>
                </help-component>
            </label>
            <div class="subtle-hint">
                Choose a model that supports function calls.
            </div>
            <div class="input-button-pair">
                <input v-if="modelIds.length === 0" v-model="llmClone.modelId" type="text" disabled="true">
                <select
                    id="llm-api-settings-component__model-id"
                    v-model="llmClone.modelId"
                    v-if="modelIds.length"
                >
                    <option
                        v-for="modelId of modelIds"
                        :value="modelId"
                    >{{ modelId }}</option>
                </select>
                <button @click="updateModelIds()">
                <icon-component name="sync"></icon-component>
                    List Models
                </button>
            </div>
        </div>
        <div class="button-bar">
            
        </div>
        <text-block-component type="error" v-if="fetchModelError" v-text="fetchModelError"></text-block-component>
    </div>
    <show-hide-component title="Advanced" :hidden="true" class="b-mar-gap2">
        <div class="input-group">
            <label for="llm-temperature">
                Temperature: {{ llmClone.temperature }}
                <help-component>
                    <p>Temperature is a hyperparameter that governs the sampling process during text generation. It determines how "random" or "creative" the model's outputs will be:</p>
                    <ul>
                        <li>
                            Lower temperature (closer to 0): Produces more deterministic, predictable responses. The model consistently selects the highest probability words.
                        </li>
                        <li>
                            Higher temperature: Leads to more varied, creative, and sometimes unexpected responses. The model may select lower probability words, increasing diversity but potentially reducing reliability
                        </li>
                    </ul>
                </help-component>
            </label>
            <input
                type="range"
                id="llm-temperature"
                :min="config.llm.temperature.min"
                :max="config.llm.temperature.max"
                :step="config.llm.temperature.step"
                v-model.number="llmClone.temperature"
            />
        </div>
        <div class="input-group">
            <label for="llm-max-tokens">
                Max Tokens: {{ llmClone.maxTokens }}
                <help-component>
                    <p>
                        You can set a maximum tokens to be generated by the AI in response to your queries.
                    </p>
                    <p>
                        A token generally corresponds to ~4 characters in English text, with common words typically using 1-2 tokens and longer/uncommon words using more.
                    </p>
                    <ul>
                        <li>Higher max token: generates longer and more elaborate responses but takes longer</li>
                        <li>Lower max token: reduces AI response delay but may cut the message half-way through.</li>
                    </ul>
                </help-component>
            </label>
            <input
                type="range"
                id="llm-max-tokens"
                :min="config.llm.maxTokens.min"
                :max="config.llm.maxTokens.max"
                :step="config.llm.maxTokens.step"
                v-model.number="llmClone.maxTokens"
            />
        </div>
    </show-hide-component>
    <code-block-component v-if="logs.length" class="b-mar-gap2" hide-top-bar>
        <div v-for="log of logs" v-text="log"></div>
    </code-block-component>
    <div class="button-bar">
        <button @click="verify()" :disabled="!llmClone.isConfigured || isVerified || llmClone.isBusy">
            <icon-component name="search"></icon-component>
            verify
        </button>
        <button @click="save()" class="button--cta" :disabled="!isVerified">
            <icon-component name="favorite"></icon-component>
            Save
        </button>
    </div>
</div>